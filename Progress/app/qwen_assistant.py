"""
ã€é€šä¹‰åƒé—® Qwenã€‘APIé›†æˆæ¨¡å—
ç”¨äºæ„å›¾ç†è§£å’Œä»»åŠ¡å¤„ç†
"""
import json
import re
import logging
import dashscope
from dashscope import Generation
from database import config
from Progress.utils.logger_utils import log_time, log_step, log_var, log_call
from Progress.utils.logger_config import setup_logger

""" import config
from utils.logger_utils import log_time, log_step, log_var, log_call
from utils.logger_config import setup_logger """

# --- åˆå§‹åŒ–æ—¥å¿—å™¨ ---
logger = logging.getLogger("ai_assistant")

DASHSCOPE_API_KEY = config.api_key
DASHSCOPE_MODEL = config.model


class QWENAssistant:
    def __init__(self):
        if not DASHSCOPE_API_KEY:
            raise ValueError("ç¼ºå°‘ DASHSCOPE_API_KEYï¼Œè¯·æ£€æŸ¥é…ç½®æ–‡ä»¶")
        dashscope.api_key = DASHSCOPE_API_KEY

        self.model_name = DASHSCOPE_MODEL or 'qwen-max'
        logger.info(f"âœ… QWENAssistant åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨æ¨¡å‹: {self.model_name}")

        self.conversation_history = []

        self.system_prompt = """
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½è¯­éŸ³æ§åˆ¶åŠ©æ‰‹ï¼Œèƒ½å¤Ÿç†è§£ç”¨æˆ·çš„è¯­éŸ³æŒ‡ä»¤å¹¶æ‰§è¡Œç›¸åº”çš„ä»»åŠ¡ã€‚

ä½ çš„ä¸»è¦èƒ½åŠ›åŒ…æ‹¬ï¼š
1. æ’­æ”¾éŸ³ä¹å’Œæ§åˆ¶åª’ä½“
2. æ–‡ä»¶æ“ä½œï¼ˆåˆ›å»ºã€è¯»å–ã€ç¼–è¾‘æ–‡ä»¶ï¼‰
3. æ–‡æœ¬ç”Ÿæˆï¼ˆå†™æ–‡ç« ã€æ€»ç»“ã€ç¿»è¯‘ç­‰ï¼‰
4. ç³»ç»Ÿæ§åˆ¶ï¼ˆæ‰“å¼€åº”ç”¨ã€è®¾ç½®æé†’ç­‰ï¼‰
5. å¤šæ­¥éª¤ä»»åŠ¡ç¼–æ’

å½“ç”¨æˆ·å‘å‡ºæŒ‡ä»¤æ—¶ï¼Œä½ éœ€è¦ï¼š
1. ç†è§£ç”¨æˆ·çš„æ„å›¾
2. ç¡®å®šéœ€è¦æ‰§è¡Œçš„å…·ä½“æ“ä½œ
3. è¿”å›ç»“æ„åŒ–çš„å“åº”ï¼ŒåŒ…å«æ“ä½œç±»å‹å’Œå‚æ•°

ğŸ¯ å“åº”æ ¼å¼å¿…é¡»æ˜¯ä¸¥æ ¼åˆæ³•çš„ JSONï¼š
{
    "intent": "æ“ä½œç±»å‹",
    "action": "å…·ä½“åŠ¨ä½œ",
    "parameters": {"å‚æ•°å": "å‚æ•°å€¼"},
    "response": "ç»™ç”¨æˆ·çš„å›å¤",
    "needs_confirmation": true/false
}


ğŸ“Œ æ”¯æŒçš„æ“ä½œç±»å‹ï¼š
- music: éŸ³ä¹ç›¸å…³æ“ä½œ
- file: æ–‡ä»¶æ“ä½œ
- text: æ–‡æœ¬ç”Ÿæˆ
- system: ç³»ç»Ÿæ§åˆ¶
- task: å¤šæ­¥éª¤ä»»åŠ¡
- chat: æ™®é€šå¯¹è¯

â—æ³¨æ„äº‹é¡¹
è¯·å§‹ç»ˆç”¨ä¸­æ–‡å›å¤ç”¨æˆ·ã€‚
åˆ›å»ºå’Œå†™å…¥æ˜¯ä¸åŒçš„æ“ä½œ
"""

    @log_time
    @log_step("å¤„ç†è¯­éŸ³æŒ‡ä»¤")
    def process_voice_command(self, voice_text):
        log_var("åŸå§‹è¾“å…¥", voice_text)

        if not voice_text.strip():
            return self._create_response("chat", "empty", {}, "æˆ‘æ²¡æœ‰å¬æ¸…æ¥šï¼Œè¯·é‡æ–°è¯´è¯ã€‚", False)

        self.conversation_history.append({"role": "user", "content": voice_text})

        try:
            messages = [{"role": "system", "content": self.system_prompt}]
            messages.extend(self.conversation_history[-10:])

            response = Generation.call(
                model=self.model_name,
                messages=messages,
                temperature=0.5,
                top_p=0.8,
                max_tokens=1024
            )

            if response.status_code != 200:
                logger.error(f"Qwen API è°ƒç”¨å¤±è´¥: {response.status_code}, {response.message}")
                return self._create_response("chat", "error", {}, f"æœåŠ¡æš‚æ—¶ä¸å¯ç”¨: {response.message}", False)

            ai_response = response.output['text'].strip()
            log_var("æ¨¡å‹è¾“å‡º", ai_response)

            self.conversation_history.append({"role": "assistant", "content": ai_response})

            # å°è¯•è§£æ JSON
            try:
                parsed = json.loads(ai_response)
                return parsed
            except json.JSONDecodeError:
                json_match = re.search(r'\{[\s\S]*\}', ai_response)
                if json_match:
                    try:
                        return json.loads(json_match.group())
                    except:
                        pass
                return self._create_response("chat", "reply", {}, ai_response, False)

        except Exception as e:
            logger.exception("å¤„ç†è¯­éŸ³æŒ‡ä»¤æ—¶å‘ç”Ÿæœªé¢„æœŸå¼‚å¸¸")
            return self._create_response("chat", "error", {}, "æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›æŠ€æœ¯é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚", False)

    def _create_response(self, intent, action, parameters, response, needs_confirmation):
        resp = {"intent": intent, "action": action, "parameters": parameters, "response": response, "needs_confirmation": needs_confirmation}
        log_var("è¿”å›å“åº”", resp)
        return resp

    @log_time
    def generate_text(self, prompt, task_type="general"):
        log_var("ä»»åŠ¡ç±»å‹", task_type)
        log_var("æç¤ºè¯é•¿åº¦", len(prompt))

        try:
            system_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬ç”ŸæˆåŠ©æ‰‹ã€‚æ ¹æ®ç”¨æˆ·çš„è¦æ±‚ç”Ÿæˆé«˜è´¨é‡çš„æ–‡æœ¬å†…å®¹ã€‚

ä»»åŠ¡ç±»å‹ï¼š{task_type}
è¦æ±‚ï¼š{prompt}

è¯·ç”Ÿæˆç›¸åº”çš„æ–‡æœ¬å†…å®¹ï¼Œç¡®ä¿å†…å®¹å‡†ç¡®ã€æœ‰é€»è¾‘ã€è¯­è¨€æµç•…ã€‚
"""
            response = Generation.call(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.8,
                max_tokens=2000
            )

            if response.status_code == 200:
                result = response.output['text']
                log_var("ç”Ÿæˆç»“æœé•¿åº¦", len(result))
                return result
            else:
                error_msg = f"æ–‡æœ¬ç”Ÿæˆå¤±è´¥: {response.message}"
                logger.error(error_msg)
                return error_msg

        except Exception as e:
            logger.exception("æ–‡æœ¬ç”Ÿæˆå‡ºé”™")
            return f"æŠ±æ­‰ï¼Œç”Ÿæˆæ–‡æœ¬æ—¶é‡åˆ°é”™è¯¯ï¼š{str(e)}"

    @log_time
    def summarize_text(self, text):
        log_var("å¾…æ€»ç»“æ–‡æœ¬é•¿åº¦", len(text))
        try:
            prompt = f"è¯·æ€»ç»“ä»¥ä¸‹æ–‡æœ¬çš„ä¸»è¦å†…å®¹ï¼š\n\n{text}"
            response = Generation.call(
                model=self.model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=500
            )
            if response.status_code == 200:
                result = response.output['text']
                log_var("æ€»ç»“ç»“æœé•¿åº¦", len(result))
                return result
            else:
                error_msg = f"æ€»ç»“å¤±è´¥: {response.message}"
                logger.error(error_msg)
                return error_msg
        except Exception as e:
            logger.exception("æ–‡æœ¬æ€»ç»“å‡ºé”™")
            return f"æŠ±æ­‰ï¼Œæ€»ç»“æ–‡æœ¬æ—¶é‡åˆ°é”™è¯¯ï¼š{str(e)}"

    @log_time
    def translate_text(self, text, target_language="è‹±æ–‡"):
        log_var("ç›®æ ‡è¯­è¨€", target_language)
        log_var("åŸæ–‡é•¿åº¦", len(text))
        try:
            prompt = f"è¯·å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆ{target_language}ï¼š\n\n{text}"
            response = Generation.call(
                model=self.model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=1000
            )
            if response.status_code == 200:
                result = response.output['text']
                log_var("ç¿»è¯‘ç»“æœé•¿åº¦", len(result))
                return result
            else:
                error_msg = f"ç¿»è¯‘å¤±è´¥: {response.message}"
                logger.error(error_msg)
                return error_msg
        except Exception as e:
            logger.exception("æ–‡æœ¬ç¿»è¯‘å‡ºé”™")
            return f"æŠ±æ­‰ï¼Œç¿»è¯‘æ–‡æœ¬æ—¶é‡åˆ°é”™è¯¯ï¼š{str(e)}"

# =============================
# ğŸ§ª æµ‹è¯•ä»£ç 
# =============================
if __name__ == "__main__":
    # åˆå§‹åŒ–å…¨å±€æ—¥å¿—ç³»ç»Ÿ
    setup_logger(name="ai_assistant", log_dir="logs")

    assistant = QWENAssistant()

    test_commands = [
        "æ’­æ”¾å‘¨æ°ä¼¦çš„æ­Œæ›²",
        "å†™ä¸€ç¯‡å…³äºæ°”å€™å˜åŒ–çš„æ–‡ç« ",
        "æŠŠè¿™æ®µè¯ç¿»è¯‘æˆè‹±æ–‡ï¼šä»Šå¤©å¤©æ°”çœŸå¥½",
        "æ€»ç»“ä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹",
        "ä½ å¥½å•Š",
        "æ‰“å¼€æµè§ˆå™¨",
        "åœ¨å½“å‰æ–‡ä»¶å¤¹åˆ›å»ºä¸€ä¸ªæµ‹è¯•æ–‡æœ¬å¹¶å†™å…¥æˆ‘çš„ä¸–ç•Œ"
    ]

    for cmd in test_commands:
        print(f"\nğŸ”Š ç”¨æˆ·æŒ‡ä»¤: {cmd}")
        result = assistant.process_voice_command(cmd)
        print("ğŸ¤– AIå“åº”:")
        print(json.dumps(result, ensure_ascii=False, indent=2))