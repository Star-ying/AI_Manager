"""
ã€è¯­éŸ³è¯†åˆ«æ¨¡å—ã€‘Speech Recognition (Offline)
ä½¿ç”¨éº¦å…‹é£è¿›è¡Œå®æ—¶è¯­éŸ³è¯†åˆ«ï¼ŒåŸºäº Vosk ç¦»çº¿æ¨¡å‹
æ”¯æŒå•æ¬¡è¯†åˆ« & æŒç»­ç›‘å¬æ¨¡å¼
éŸ³é‡å¯è§†åŒ–ã€æ¨¡å‹è·¯å¾„æ£€æŸ¥ã€èµ„æºå®‰å…¨é‡Šæ”¾
"""
import threading
import time
import logging
import json
import os
from vosk import Model, KaldiRecognizer
import pyaudio

from database import config
from Progress.utils.logger_utils import log_time, log_step, log_var, log_call
from Progress.utils.logger_config import setup_logger

# --- é…ç½®å‚æ•° ---
VOICE_TIMEOUT = config.timeout  # æœ€å¤§ç­‰å¾…è¯­éŸ³è¾“å…¥æ—¶é—´ï¼ˆç§’ï¼‰
VOICE_PHRASE_TIMEOUT = config.phrase_timeout  # å•å¥è¯æœ€é•¿å½•éŸ³æ—¶é—´
VOSK_MODEL_PATH = "./vosk-model-small-cn-0.22"

# --- åˆå§‹åŒ–æ—¥å¿—å™¨ ---
logger = logging.getLogger("ai_assistant")
# å®šä¹‰æœ€å°æœ‰æ•ˆéŸ³é‡é˜ˆå€¼
MIN_VOLUME_THRESHOLD = 600  # å¯è°ƒï¼ˆæ ¹æ®ç¯å¢ƒæµ‹è¯•ï¼‰


class SpeechRecognizer:
    def __init__(self):
        self.model = None
        self.recognizer = None
        self.audio = None
        self.is_listening = False
        self.callback = None  # ç”¨æˆ·æ³¨å†Œçš„å›è°ƒå‡½æ•°ï¼šcallback(text)
        self._last_text = ""
        self._listen_thread = None

        self.sample_rate = 16000  # Vosk è¦æ±‚é‡‡æ ·ç‡ 16kHz
        self.chunk_size = 1600     # æ¨èå¸§å¤§å°ï¼ˆå¯¹åº” ~100msï¼‰

        # ğŸ”’ TTS æ’­æ”¾çŠ¶æ€æ ‡å¿—ï¼ˆç”±å¤–éƒ¨æ§åˆ¶ï¼‰
        self._is_tts_playing = False
        self._tts_lock = threading.Lock()

        self._load_model()
        self._init_audio_system()

    @property
    def is_tts_playing(self) -> bool:
        with self._tts_lock:
            return self._is_tts_playing

    def set_tts_playing(self, status: bool):
        """ä¾› TTS æ¨¡å—è°ƒç”¨ï¼šé€šçŸ¥å½“å‰æ˜¯å¦æ­£åœ¨æ’­æ”¾"""
        with self._tts_lock:
            self._is_tts_playing = status
        if not status:
            logger.debug("ğŸŸ¢ TTS æ’­æ”¾ç»“æŸï¼Œè¯­éŸ³è¯†åˆ«æ¢å¤")

    @log_step("åŠ è½½ Vosk ç¦»çº¿æ¨¡å‹")
    @log_time
    def _load_model(self):
        """åŠ è½½æœ¬åœ° Vosk æ¨¡å‹"""
        if not os.path.exists(VOSK_MODEL_PATH):
            raise FileNotFoundError(f"âŒ Vosk æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {VOSK_MODEL_PATH}\n","è¯·ä» https://alphacephei.com/vosk/models ä¸‹è½½ä¸­æ–‡å°æ¨¡å‹å¹¶è§£å‹è‡³æ­¤è·¯å¾„")

        try:
            logger.info(f"ğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å‹: {VOSK_MODEL_PATH}")
            self.model = Model(VOSK_MODEL_PATH)
            log_call("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            logger.critical(f"ğŸ”´ åŠ è½½ Vosk æ¨¡å‹å¤±è´¥: {e}")
            raise RuntimeError("Failed to load Vosk model") from e

    @log_step("åˆå§‹åŒ–éŸ³é¢‘ç³»ç»Ÿ")
    @log_time
    def _init_audio_system(self):
        """åˆå§‹åŒ– PyAudio å¹¶åˆ›å»ºå…¨å±€ recognizer"""
        try:
            self.audio = pyaudio.PyAudio()
            # åˆ›å»ºé»˜è®¤è¯†åˆ«å™¨ï¼ˆå¯åœ¨æ¯æ¬¡è¯†åˆ«å‰ Resetï¼‰
            self.recognizer = KaldiRecognizer(self.model, self.sample_rate)
            logger.debug("âœ… éŸ³é¢‘ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            logger.exception("âŒ åˆå§‹åŒ–éŸ³é¢‘ç³»ç»Ÿå¤±è´¥")
            raise

    @property
    def last_text(self) -> str:
        return self._last_text

    def is_available(self) -> bool:
        """æ£€æŸ¥éº¦å…‹é£æ˜¯å¦å¯ç”¨"""
        if not self.audio:
            return False
        try:
            stream = self.audio.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=self.sample_rate,
                input=True,
                frames_per_buffer=self.chunk_size
            )
            stream.close()
            return True
        except Exception as e:
            logger.error(f"ğŸ”´ éº¦å…‹é£ä¸å¯ç”¨æˆ–æ— æƒé™: {e}")
            return False

    @log_step("æ‰§è¡Œå•æ¬¡è¯­éŸ³è¯†åˆ«")
    @log_time
    def listen_and_recognize(self, timeout=None) -> str:
        timeout = timeout or VOICE_TIMEOUT
        start_time = time.time()
        in_speech = False
        result_text = ""

        logger.debug(f"ğŸ™ï¸ å¼€å§‹å•æ¬¡è¯­éŸ³è¯†åˆ« (timeout={timeout:.1f}s)...")

        # ğŸ”´ å¦‚æœæ­£åœ¨æ’­æ”¾ TTSï¼Œç›´æ¥è¿”å›ç©º
        if self.is_tts_playing:
            logger.info("ğŸ”‡ TTS æ­£åœ¨æ’­æ”¾ï¼Œè·³è¿‡æœ¬æ¬¡è¯†åˆ«")
            return ""

        logger.info("ğŸ”Š è¯·è¯´è¯...")

        stream = None
        try:
            recognizer = KaldiRecognizer(self.model, self.sample_rate)

            stream = self.audio.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=self.sample_rate,
                input=True,
                frames_per_buffer=self.chunk_size
            )

            while (time.time() - start_time) < timeout:
                # å†æ¬¡æ£€æŸ¥æ’­æ”¾çŠ¶æ€ï¼ˆå¯èƒ½ä¸­é€”å¼€å§‹ï¼‰
                if self.is_tts_playing:
                    logger.info("ğŸ”‡ TTS å¼€å§‹æ’­æ”¾ï¼Œä¸­æ–­è¯†åˆ«")
                    break

                data = stream.read(self.chunk_size, exception_on_overflow=False)

                if recognizer.AcceptWaveform(data):
                    final_result = json.loads(recognizer.Result())
                    text = final_result.get("text", "").strip()
                    if text:
                        result_text = text
                        break
                else:
                    partial = json.loads(recognizer.PartialResult())
                    if partial.get("partial", "").strip():
                        in_speech = True

                if not in_speech and (time.time() - start_time) >= timeout:
                    logger.info("ğŸ’¤ è¶…æ—¶æœªæ£€æµ‹åˆ°è¯­éŸ³è¾“å…¥")
                    break

            if result_text:
                self._last_text = result_text
                logger.info(f"ğŸ¯ è¯†åˆ«ç»“æœ: '{result_text}'")
                return result_text
            else:
                logger.info("â“ æœªè¯†åˆ«åˆ°æœ‰æ•ˆå†…å®¹")
                self._last_text = ""
                return ""

        except Exception as e:
            logger.exception("ğŸ”´ æ‰§è¡Œå•æ¬¡è¯­éŸ³è¯†åˆ«æ—¶å‘ç”Ÿå¼‚å¸¸")
            self._last_text = ""
            return ""
        finally:
            if stream:
                try:
                    stream.stop_stream()
                    stream.close()
                except Exception as e:
                    logger.warning(f"âš ï¸ å…³é—­éŸ³é¢‘æµå¤±è´¥: {e}")

    @log_step("å¯åŠ¨æŒç»­è¯­éŸ³ç›‘å¬")
    def start_listening(self, callback=None, language=None):
        """
        å¯åŠ¨åå°çº¿ç¨‹æŒç»­ç›‘å¬è¯­éŸ³è¾“å…¥
        :param callback: å›è°ƒå‡½æ•°ï¼Œæ¥å—ä¸€ä¸ªå­—ç¬¦ä¸²å‚æ•° text
        :param language: è¯­è¨€ä»£ç ï¼ˆå¿½ç•¥ï¼Œç”±æ¨¡å‹å†³å®šï¼‰
        """
        if self.is_listening:
            logger.warning("âš ï¸ å·²åœ¨ç›‘å¬ä¸­ï¼Œå¿½ç•¥é‡å¤å¯åŠ¨")
            return

        if not callable(callback):
            logger.error("ğŸ”´ å›è°ƒå‡½æ•°æ— æ•ˆï¼Œè¯·ä¼ å…¥å¯è°ƒç”¨å¯¹è±¡")
            return

        self.callback = callback
        self.is_listening = True

        self._listen_thread = threading.Thread(target=self._background_listen, args=(language,), daemon=True)
        self._listen_thread.start()
        logger.info("ğŸŸ¢ å·²å¯åŠ¨åå°è¯­éŸ³ç›‘å¬")

    @log_step("åœæ­¢è¯­éŸ³ç›‘å¬")
    def stop_listening(self):
        """å®‰å…¨åœæ­¢åå°ç›‘å¬"""
        if not self.is_listening:
            return

        self.is_listening = False
        logger.info("ğŸ›‘ æ­£åœ¨åœæ­¢è¯­éŸ³ç›‘å¬...")

        if self._listen_thread and self._listen_thread != threading.current_thread():
            self._listen_thread.join(timeout=3)
            if self._listen_thread.is_alive():
                logger.warning("ğŸŸ¡ ç›‘å¬çº¿ç¨‹æœªèƒ½åŠæ—¶é€€å‡ºï¼ˆå¯èƒ½é˜»å¡ï¼‰")
        elif self._listen_thread == threading.current_thread():
            logger.error("âŒ æ— æ³•åœ¨å½“å‰çº¿ç¨‹ä¸­ join è‡ªå·±ï¼è¯·æ£€æŸ¥è°ƒç”¨æ ˆ")
        else:
            logger.debug("No thread to join")

        logger.info("âœ… è¯­éŸ³ç›‘å¬å·²åœæ­¢")

    def _background_listen(self, language=None):
        """åå°å¾ªç¯ç›‘å¬çº¿ç¨‹"""
        logger.debug("ğŸ§ åå°ç›‘å¬çº¿ç¨‹å·²å¯åŠ¨")

        stream = None
        try:
            stream = self.audio.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=self.sample_rate,
                input=True,
                frames_per_buffer=self.chunk_size
            )
        except Exception as e:
            logger.error(f"ğŸ”´ æ— æ³•æ‰“å¼€éŸ³é¢‘æµ: {e}")
            return

        try:
            while self.is_listening:
                # ğŸ”´ æ£€æŸ¥æ˜¯å¦æ­£å¤„äº TTS æ’­æ”¾ä¸­ â†’ è·³è¿‡æœ¬æ¬¡è¯»å–
                if self.is_tts_playing:
                    time.sleep(0.1)  # å‡å°‘ CPU å ç”¨
                    continue

                try:
                    data = stream.read(self.chunk_size, exception_on_overflow=False)

                    if self.recognizer.AcceptWaveform(data):
                        result_json = self.recognizer.Result()
                        result_dict = json.loads(result_json)
                        text = result_dict.get("text", "").strip()
                        if text and self.callback:
                            logger.info(f"ğŸ”” å›è°ƒè§¦å‘: '{text}'")
                            self.callback(text)
                        self.recognizer.Reset()
                    else:
                        partial = json.loads(self.recognizer.PartialResult())
                        partial_text = partial.get("partial", "")
                        if partial_text.strip():
                            logger.debug(f"ğŸ—£ï¸ å½“å‰è¯­éŸ³ç‰‡æ®µ: '{partial_text}'")

                except Exception as e:
                    logger.exception("Background listening error")
                time.sleep(0.05)

        finally:
            if stream:
                stream.stop_stream()
                stream.close()
            logger.debug("ğŸ”š åå°ç›‘å¬çº¿ç¨‹é€€å‡º")



recognizer = SpeechRecognizer()
