"""
ç¦»çº¿è¯­éŸ³è¯†åˆ«æ¨¡å—ï¼ˆåŸºäº Voskï¼‰
æ”¯æŒé˜²è‡ªåé¦ˆæœºåˆ¶ï¼šå½“ TTS æ’­æ”¾æ—¶ä¸ç›‘å¬
"""

import threading
import time
import logging
import json
import os
from vosk import Model, KaldiRecognizer
import pyaudio

from Progress.app import get_tts_engine
from database.config import config
from Progress.utils.logger_config import setup_logger
from Progress.utils.resource_helper import get_internal_path

logger = logging.getLogger("ai_assistant")

VOSK_MODEL_PATH = get_internal_path("models", "vosk-model-small-cn-0.22")

# å…¨å±€å®ä¾‹ï¼ˆä¾› TTS è°ƒç”¨ï¼‰
recognizer = None

class SpeechRecognizer:
    def __init__(self, tts_engine):
        global recognizer
        recognizer = self  # è‡ªæ³¨å†Œä¸ºå…¨å±€å¯¹è±¡

        self.model = None
        self.audio = None
        self.tts_engine = tts_engine
        self._is_tts_playing = False
        self._tts_lock = threading.Lock()

        self.sample_rate = 16000
        self.chunk_size = 1600

        self._current_timeout = config.get("voice_recognition", "timeout", "initial")
        self._min_volume_threshold = config.get("voice_recognition", "volume_threshold", "base")
        self._post_speech_short_wait = config.get("voice_recognition", "post_speech_short_wait", "value")
        self._post_speech_long_wait = config.get("voice_recognition", "post_speech_long_wait", "value")
        self.long_speech_threshold = config.get("voice_recognition", "long_speech_threshold", "value")

        self._load_model()
        self._init_audio_system()
        logger.info("âœ… è¯­éŸ³è¯†åˆ«å™¨åˆå§‹åŒ–å®Œæˆ")

    @property
    def current_timeout(self):
        return self._current_timeout

    @current_timeout.setter
    def current_timeout(self, value):
        min_val = config.get("voice_recognition", "timeout", "min")
        max_val = config.get("voice_recognition", "timeout", "max")
        old = self._current_timeout
        self._current_timeout = max(min_val, min(max_val, float(value)))
        logger.debug(f"â±ï¸ ç›‘å¬è¶…æ—¶: {old:.1f} â†’ {self._current_timeout:.1f}s")

    @property
    def is_tts_playing(self):
        with self._tts_lock:
            return self._is_tts_playing

    def set_tts_playing(self, status: bool):
        with self._tts_lock:
            self._is_tts_playing = status
        if not status:
            logger.debug("ğŸŸ¢ TTS ç»“æŸï¼Œæ¢å¤ç›‘å¬")

    def _load_model(self):
        if not os.path.exists(VOSK_MODEL_PATH):
            raise FileNotFoundError(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {VOSK_MODEL_PATH}")
        self.model = Model(VOSK_MODEL_PATH)
        logger.info("âœ… Vosk æ¨¡å‹åŠ è½½æˆåŠŸ")

    def _init_audio_system(self):
        try:
            self.audio = pyaudio.PyAudio()
            logger.debug("âœ… PyAudio åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            logger.exception("âŒ åˆå§‹åŒ–éŸ³é¢‘ç³»ç»Ÿå¤±è´¥")
            raise

    def listen_and_recognize(self, timeout=None) -> str:
        use_timeout = timeout or self.current_timeout
        min_t = config.get("voice_recognition", "timeout", "min")
        max_t = config.get("voice_recognition", "timeout", "max")
        use_timeout = max(min_t, min(max_t, float(use_timeout)))

        if self.tts_engine.is_playing():
            logger.info("ğŸ”‡ TTS æ­£åœ¨æ’­æ”¾ï¼Œè·³è¿‡æœ¬æ¬¡è¯­éŸ³è¯†åˆ«")
            return None
        
        stream = None
        try:
            _recognizer = KaldiRecognizer(self.model, self.sample_rate)
            stream = self.audio.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=self.sample_rate,
                input=True,
                frames_per_buffer=self.chunk_size
            )

            start_time = time.time()
            in_speech = False
            result_text = ""

            logger.info("ğŸ™ï¸ è¯·è¯´è¯...")

            while (time.time() - start_time) < use_timeout:
                if self.is_tts_playing:
                    logger.info("ğŸ”‡ TTS å¼€å§‹æ’­æ”¾ï¼Œä¸­æ–­è¯†åˆ«")
                    break

                data = stream.read(self.chunk_size, exception_on_overflow=False)

                if _recognizer.AcceptWaveform(data):
                    final_result = json.loads(_recognizer.Result())
                    text = final_result.get("text", "").strip()
                    if text:
                        result_text = text
                        break
                else:
                    partial = json.loads(_recognizer.PartialResult())
                    if partial.get("partial", "").strip():
                        in_speech = True

            return result_text

        except Exception as e:
            logger.exception("ğŸ”´ è¯†åˆ«å¼‚å¸¸")
            return ""
        finally:
            if stream:
                try:
                    stream.stop_stream()
                    stream.close()
                except:
                    pass
